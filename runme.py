# -*- coding: utf-8 -*-
"""APML_MiniProject_FinalVersion

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tOS67VnjV4XWkdjhRsFkn29kkVesfNfl
"""


"""
# Q4
"""

def main():

    import numpy as np
    import matplotlib.pyplot as plt
    from scipy.stats import truncnorm
    import time
    
    print('Entered Q4')
    
    np.random.seed(7)
    L = 1000 #number of samples
    
    def gibbs_sampler(L):
      s1 = np.zeros(L)
      s2 = np.zeros(L)
      t = truncnorm.rvs(a=0, b=np.inf, size=L)
    
      #parameters
      mu_s1, mu_s2 = 1,1
      sig_s1, sig_s2 = 1,1
      sig_t = np.sqrt(5)
    
      #initialize
      s1[0] = 1
      s2[0] = 1
    
      #covariance matrix of p(s1,s2 | t)
      sigma_s_t = np.linalg.inv(np.array([[1/sig_t**2+1/sig_s1**2,-1/sig_t**2],[-1/sig_t**2,1/sig_s2**2+1/sig_t**2]]))
      sig_s1_t = np.sqrt(sigma_s_t[0][0])
      sig_s2_t = np.sqrt(sigma_s_t[1][1])
    
      chain_mu_s1 = np.zeros(L)
      chain_sig_s1 = np.zeros(L)
      chain_mu_s2 = np.zeros(L)
      chain_sig_s2 = np.zeros(L)
      chain_mu_s1[0] = mu_s1
      chain_mu_s2[0] = mu_s2
      chain_sig_s1[0] = sig_s1
      chain_sig_s2[0] = sig_s2
    
      start = time.time()
      #Gibbs sampler
      for k in range(L-1):
        #sampling t
        t[k+1] = truncnorm.rvs(a=(s2[k]-s1[k])/sig_t,b=np.inf,loc=(s1[k]-s2[k]),scale=sig_t) 
    
        #updating the mean of p(s1,s2 | t)
        mu_s_t = np.matmul(sigma_s_t,np.array([mu_s1/sig_s1**2+t[k+1]/sig_t**2,mu_s2/sig_s2**2-t[k+1]/sig_t**2]))
        
        #sampling s1  
        s1[k+1] = np.random.normal()*sig_s1_t + mu_s_t[0]
      
        #sampling s2
        s2[k+1] = np.random.normal()*sig_s2_t + mu_s_t[1]
    
        #save means and variances to assess stationnarity
        chain_mu_s1[k+1] = np.mean(s1[:k+1])
        chain_mu_s2[k+1] = np.mean(s2[:k+1])
        chain_sig_s1[k+1] = np.std(s1[:k+1])
        chain_sig_s2[k+1] = np.std(s2[:k+1])
        #print(k,s1)
        
      end = time.time()
      elapsed_t = end-start
    
      return s1,s2,t,elapsed_t,chain_mu_s1,chain_mu_s2,chain_sig_s1,chain_sig_s2
    
    s1,s2,t,elapsed_t,chain_mu_s1,chain_mu_s2,chain_sig_s1,chain_sig_s2 = gibbs_sampler(1000)
    f = plt.figure(figsize=(15,6))
    ax = f.add_subplot(121)
    ax.plot(chain_mu_s1,label="Mean of s1")
    ax.plot(chain_mu_s2,label="Mean of s2")
    ax.set_title("Means of skills s1 and s2 given y=1")
    ax.legend()
    
    ax2 = f.add_subplot(122)
    ax2.plot(chain_sig_s1,label="Deviation of s1")
    ax2.plot(chain_sig_s2,label="Deviation of s2")
    ax2.set_title("Deviations of skills s1 and s2 given y=1")
    ax2.legend()
    
    f.savefig('Q4_Means_Skills')
    
    burn_in = 500
    s1_stationary = s1[burn_in+1:]
    plt.figure()
    plt.hist(s1_stationary,density=True)
    plt.title("Histogram of s1 after burn-in given y=1")
    plt.savefig('Q4_Histo_s1')
    
    
    s2_stationary = s2[burn_in+1:]
    plt.figure()
    plt.hist(s2_stationary,density=True)
    plt.title("Histogram of s2 after burn-in given y=1")
    plt.savefig('Q4_Histo_s2')
    
    plt.plot(s1_stationary,label='s1')
    plt.plot(s2_stationary,label='s2')
    plt.title("Samples s1 and s2 from the posterior after burn-in")
    plt.legend()
    plt.savefig('Q4_posterior_s1_s2')
    
    def p_s_approximation(s,x):
      """
      s: vector of samples
      return gaussian of mean = s arithmetic mean and std= s arithmetic std
      """
      est_mean = np.mean(s)
      est_std = np.std(s)
      return 1/np.sqrt(2*np.pi*est_std**2)*np.exp(-1/2/est_std**2*(x-est_mean)**2)
    
    L_list = [1000,2000,3000,5000,10000]
    xv = np.linspace(-4,6,100)
    fig, axs = plt.subplots(1,5, figsize=(15, 4), facecolor='w', edgecolor='k')
    #fig.subplots_adjust(hspace = .5, wspace=.001)
    
    axs = axs.ravel()
    
    for i in range(5):
      sampler = gibbs_sampler(L_list[i])
      s1,elapsed_t = sampler[0],sampler[3]
      #plot s1
      plt.figure()
      axs[i].plot(xv,p_s_approximation(s1[burn_in:],xv))
      axs[i].hist(s1[burn_in:],bins=100,density=True)
      axs[i].set_title(str(round(elapsed_t,2))+"s, for "+str(L_list[i])+" samples")
      
    plt.savefig('Q4_runtime_vs_samples')
    
    def prior_s(mean,std,x):
      return(1/np.sqrt(2*np.pi*std**2)*np.exp(-1/2/std**2*(x-mean)**2))
    
    s1,s2,t,elapsed_t,chain_mu_s1,chain_mu_s2,chain_sig_s1,chain_sig_s2 = gibbs_sampler(5000)
    mu_s1, mu_s2 = 1,1
    sig_s1, sig_s2 = 1,1
    xv = np.linspace(-4,6,100)
    
    f, axs = plt.subplots(1,2,figsize=(10,5))
    #plt.subplot(1,2,1)
    axs[0].plot(xv,prior_s(mu_s1,sig_s1,xv),label="p(s1)")
    axs[0].plot(xv,p_s_approximation(s1[burn_in:],xv),label="p(s1 | y=1)")
    axs[0].legend()
    #plt.subplot(1,2,2)
    plt.plot(xv,prior_s(mu_s2,sig_s2,xv),label="p(s2)")
    plt.plot(xv,p_s_approximation(s2[burn_in:],xv),label="p(s2 | y=1)")
    plt.legend()
    plt.savefig('Q4_prior_vs_posterior_sampled')
    
    """# Q5"""
    
    ## Q5
    import numpy as np
    import matplotlib.pyplot as plt
    from scipy.stats import truncnorm
    import pandas as pd
    
    print('Entered Q5')
    
    # Fixing data frames cause im stupid and used pandas
    SerieA = pd.read_csv('SerieA.csv')
    df = SerieA
    df = df.drop(columns=['yyyy-mm-dd', 'HH:MM'])
    df = df.assign(s1_win = np.sign(df['score1']-df['score2']))
    df = df.drop(columns=['score1', 'score2'])
    df1 = df.loc[df['s1_win']>0, ['team1', 'team2', 's1_win']].drop(columns = ['s1_win'])
    df2 = df.loc[df['s1_win']<0, ['team1', 'team2', 's1_win']].drop(columns = ['s1_win'])
    df2 = df2.rename(columns = {'team1':'t2'})
    df2 = df2.rename(columns = {'team2':'t1'})
    df1 = df1.rename(columns = {'team1':'t1'})
    df1 = df1.rename(columns = {'team2':'t2'})
    df = pd.concat([df1,df2]).sort_index()
    df = df.reset_index().drop(columns = ['index'])
    
    mu = pd.DataFrame([1]*20, columns=['mu'])
    sd = pd.DataFrame([1]*20, columns=['sd'])
    df_scores = df.drop(columns=['t2']).drop_duplicates()
    df_scores = df_scores.reset_index().drop(columns=['index'])
    df_scores = pd.concat([df_scores, mu, sd], axis = 1)
    df_scores = df_scores.rename(columns={'0':'score'})
    
    
    #Gibbs sampler function
    def  Gibbs(L, burn_in, team1, team2):
    
      #save means and variances to assess stationnarity
      chain_mu_s1 = np.ones(L-burn_in+3)
      chain_sig_s1 = np.ones(L-burn_in+3)
      chain_mu_s2 = np.ones(L-burn_in+3)
      chain_sig_s2 = np.ones(L-burn_in+3)
      #parameters
      mu_s1, mu_s2 = df_scores[df_scores['t1']==team1].iloc[0]['mu'],df_scores[df_scores['t1']==team2].iloc[0]['mu']
      sig_s1, sig_s2 = df_scores[df_scores['t1']==team1].iloc[0]['sd'],df_scores[df_scores['t1']==team2].iloc[0]['sd']
      sig_t = np.sqrt(5)
      #initialize
      s1 = np.zeros(L)
      s2 = np.zeros(L)
      t = np.zeros(L)
      s1[0] = mu_s1
      s2[0] = mu_s2
    
      sigma_s = np.linalg.inv(np.array([[1/sig_t**2+1/sig_s1**2,-1/sig_t**2],[-1/sig_t**2,1/sig_s2**2+1/sig_t**2]]))
      sig_s1 = np.sqrt(sigma_s[0][0])
      sig_s2 = np.sqrt(sigma_s[1][1])
    
      # gibbs sampler
      for k in range(L-1):
    
        t[k+1] = truncnorm.rvs(a=0,b=np.inf,loc=(s1[k]-s2[k]),scale=sig_t) 
    
        mu_s = np.matmul(sigma_s,np.array([mu_s1/sig_s1**2+t[k+1]/sig_t**2,mu_s2/sig_s2**2-t[k+1]/sig_t**2]))
    
        s1[k+1] = np.random.normal()*sig_s1 + mu_s[0]
    
        s2[k+1] = np.random.normal()*sig_s2 + mu_s[1]
    
        if k>burn_in:
          chain_mu_s1[k-burn_in] = np.mean(s1[burn_in:k+1])
          chain_mu_s2[k-burn_in] = np.mean(s2[burn_in:k+1])
          chain_sig_s1[k-burn_in] = np.std(s1[burn_in:k+1])
          chain_sig_s2[k-burn_in] = np.std(s2[burn_in:k+1])
    
      return np.mean(chain_mu_s1),np.mean(chain_sig_s1), np.mean(chain_mu_s2), np.mean(chain_sig_s2)
    
    
    for i in range(len(df)):
      result  = Gibbs(5000, 500, df.iloc[i]['t1'], df.iloc[i]['t2'])
      df_scores.loc[df_scores['t1']==df.iloc[i]['t1'],['mu']]=result[0]
      df_scores.loc[df_scores['t1']==df.iloc[i]['t1'],['sd']]=result[1]
      df_scores.loc[df_scores['t1']==df.iloc[i]['t2'],['mu']]=result[2]
      df_scores.loc[df_scores['t1']==df.iloc[i]['t2'],['sd']]=result[3]
    ranking = df_scores.sort_values('mu', ascending=False).reset_index().drop(columns=['index'])
    ranking
    
    """When randomizing the order in which the matches takes place the ranking also changes. This is because winning/loosing a match against a team that has already lost/won a match provides a different change in score. Hence the order of the matches has an effect on the rankings.
    """
    
    """
    # Q6
    """
    
    import numpy as np
    import matplotlib.pyplot as plt
    from scipy.stats import truncnorm, norm
    import pandas as pd
    
    print('Entered Q6')
    
    np.random.seed(469)
    # Fixing data frames cause im stupid and used pandas
    SerieA = pd.read_csv('SerieA.csv')
    df = SerieA
    df = df.drop(columns=['yyyy-mm-dd', 'HH:MM'])
    df = df.assign(s1_win = np.sign(df['score1']-df['score2']))
    df = df.drop(columns=['score1', 'score2'])
    df1 = df.loc[df['s1_win']>0, ['team1', 'team2', 's1_win']].drop(columns = ['s1_win'])
    df2 = df.loc[df['s1_win']<0, ['team1', 'team2', 's1_win']].drop(columns = ['s1_win'])
    df2 = df2.rename(columns = {'team1':'t2'})
    df2 = df2.rename(columns = {'team2':'t1'})
    df1 = df1.rename(columns = {'team1':'t1'})
    df1 = df1.rename(columns = {'team2':'t2'})
    df = pd.concat([df1,df2]).sort_index()
    df = df.reset_index().drop(columns = ['index'])
    
    mu = pd.DataFrame([1]*20, columns=['mu'])
    sd = pd.DataFrame([1]*20, columns=['sd'])
    df_scores = df.drop(columns=['t2']).drop_duplicates()
    df_scores = df_scores.reset_index().drop(columns=['index'])
    df_scores = pd.concat([df_scores, mu, sd], axis = 1)
    
    
    #Gibbs sampler function
    def  Gibbs(L, burn_in, team1, team2):
    
      #save means and variances to assess stationnarity
      chain_mu_s1 = np.ones(L-burn_in)
      chain_sig_s1 = np.ones(L-burn_in)
      chain_mu_s2 = np.ones(L-burn_in)
      chain_sig_s2 = np.ones(L-burn_in)
      #parameters
      mu_s1, mu_s2 = df_scores[df_scores['t1']==team1].iloc[0]['mu'],df_scores[df_scores['t1']==team2].iloc[0]['mu']
      sig_s1, sig_s2 = df_scores[df_scores['t1']==team1].iloc[0]['sd'],df_scores[df_scores['t1']==team2].iloc[0]['sd']
      sig_t = np.sqrt(5)
      #initialize
      s1 = np.zeros(L)
      s2 = np.zeros(L)
      t = np.zeros(L)
      t[0] = 1
      s1[0] = mu_s1
      s2[0] = mu_s2
    
      sigma_s = np.linalg.inv(np.array([[1/sig_t**2+1/sig_s1**2,-1/sig_t**2],[-1/sig_t**2,1/sig_s2**2+1/sig_t**2]]))
      sig_s1 = np.sqrt(sigma_s[0][0])
      sig_s2 = np.sqrt(sigma_s[1][1])
    
      pred = np.sign(s1[0]-s2[0])
      if pred==1:
        pred=1
      elif pred==-1:
        pred=0
      else:
        pred=np.random.randint(0, 1)
    
      # gibbs sampler
      for k in range(L-1):
    
        t[k+1] = truncnorm.rvs(a=0,b=np.inf,loc=(s1[k]-s2[k]),scale=sig_t) 
    
        mu_s = np.matmul(sigma_s,np.array([mu_s1/sig_s1**2+t[k+1]/sig_t**2,mu_s2/sig_s2**2-t[k+1]/sig_t**2]))
    
        s1[k+1] = np.random.normal()*sig_s1 + mu_s[0]
    
        s2[k+1] = np.random.normal()*sig_s2 + mu_s[1]
    
        if k>burn_in:
          chain_mu_s1[k-burn_in] = np.mean(s1[burn_in:k+1])
          chain_mu_s2[k-burn_in] = np.mean(s2[burn_in:k+1])
          chain_sig_s1[k-burn_in] = np.std(s1[burn_in:k+1])
          chain_sig_s2[k-burn_in] = np.std(s2[burn_in:k+1])
    
      return np.mean(chain_mu_s1),np.mean(chain_sig_s1), np.mean(chain_mu_s2), np.mean(chain_sig_s2), pred
    
    
    pred_rate = np.zeros(len(df))
    
    for i in range(len(df)):
      result  = Gibbs(5000, 2000, df.iloc[i]['t1'], df.iloc[i]['t2'])
      df_scores.loc[df_scores['t1']==df.iloc[i]['t1'],['mu']]=result[0]
      df_scores.loc[df_scores['t1']==df.iloc[i]['t1'],['sd']]=result[1]
      df_scores.loc[df_scores['t1']==df.iloc[i]['t2'],['mu']]=result[2]
      df_scores.loc[df_scores['t1']==df.iloc[i]['t2'],['sd']]=result[3]
      pred_rate[i] = result[4]
    ranking = df_scores.sort_values('mu', ascending=False).reset_index().drop(columns=['index'])
    ranking
    
    np.mean(pred_rate)
    
    """To assess if our predictor is "better" than random guessing we could use see if the predictor gives a result with a prediction rate that is higher than the prediction rate of random guessing (guessing with probability=0.5) and is statistically significant. We can do this by using a binomial test. If the p-value (pv) produced by the binomial test is smaller than a specified critical value (pv<0.001) that means that we can reject the null hypothesis (the hypothesis that our predictor is the same as random guessing)."""
    
    from scipy.stats import binom_test
    test_pred = binom_test(sum(pred_rate), n=len(df), p=0.5)
    print(test_pred)
    print('is this smaller than our critical value?')
    print(test_pred<0.001)
    
    """Hence clearly our predictor is better than random guessing.
    """
    
    """
    # Q8
    """
    
    import numpy as np
    import matplotlib.pyplot as plt
    from scipy.stats import truncnorm, norm
    import time
    
    print('Entered Q8')
    
    def multiply_gauss(m1, s1, m2, s2):
      # Computes N(m,s) prop to N(m1,s1)*N(m2,s2)
      # Inputs: means m1, m2 and variances s1, s2
      # Outputs: mean m, variance s
    
      s = 1/(1/s1 + 1/s2)
      m = (m1/s1 + m2/s2)*s
      return m,s
    
    def divide_gauss(m1, s1, m2, s2):
      # Computes N(m,s) prop to N(m1,s1)/N(m2,s2)
      # Inputs: means m1, m2 and variances s1, s2
      # Outputs: mean m, variance s
    
      m, s = multiply_gauss(m1,s1,m2,-s2)
      return m,s
    
    def trunc_gauss_mm(a, b, m0, s0):
      # Computes the mean m and variance s of N(m,s) which is the approximation
      # of the truncated gaussian N(m0, s0) defined on the interval [a,b]
      # Inputs: Interval endpoints a,b ; mean m0 and variance s0
      # Outputs: mean m, variance s
    
      # scale interval with mean and variance (NOTE: why?)
      a_scaled, b_scaled = (a - m0) / np.sqrt(s0), (b - m0)/np.sqrt(s0)
      m = truncnorm.mean(a_scaled, b_scaled, loc=m0, scale=np.sqrt(s0))
      s = truncnorm.var(a_scaled, b_scaled, loc=m0, scale=np.sqrt(s0))
    
      return m,s
    
    
    def posterior_s1_s2(m1, s1, m2, s2, st, y0):
      # Computes the posteriors of the skill levels s1 and s2 given y=1 (Player 1 
      # wins).
      # Inputs:
      # m1,s1 : mean and variances of prior N(s1;m1,s1)
      # m2,s2 : mean and variances of prior N(s2;m2,s2)
      # st : the variance of the t-node N(t; s1-s2, st)
      # y0 : observed value of y (+1 or -1)
      #
      # Outputs:
      # p_s1_m, p_s1_s : mean and variance of marginal p(s1) ( p(s1 | y) )
      # p_s2_m, p_s2_s : mean and variance of marginal p(s2) ( p(s2 | y) )
    
      ### <Technically not needed>
      # Messages, prior 1 -> s1 , prior 2 -> s2
      f1_s1_m = m1
      f1_s1_s = s1
    
      f2_s2_m = m2
      f2_s2_s = s2
    
      # Messages s1 -> f3 , s2 -> f3
      s1_f3_m = f1_s1_m
      s1_f3_s = f1_s1_s
    
      s2_f3_m = f2_s2_m
      s2_f3_s = f2_s2_s
      ### <\Technically not needed>
    
      # Message f3 -> t (here I use the guassian calculated using Corr 2 instead)
      f3_t_m = m1 - m2
      f3_t_s = st + s1 + s2
    
      # Messasge y -> f4 with y=1, f4 -> t (truncates t-axis to positive axis)
      if (y0 == 1):
        t_a = 0
        t_b = 1000 # large value, lets avoid using np.inf
      else:
        t_a = -1000
        t_b = 0
    
      # Moment-matching at node t
      q_m, q_s = trunc_gauss_mm(t_a, t_b, f3_t_m, f3_t_s)
      
      # Message t -> f3
      t_f3_m, t_f3_s = divide_gauss(q_m, q_s, f3_t_m, f3_t_s)
    
      # Messages f3 -> s1 and f3 -> s2
    
      ## What is the correct approach here??
      f3_s1_m = 1
      f3_s1_s = 1
    
      f3_s2_m = 1
      f3_s2_s = 1
    
      # Compute marginals p(s1) and p(s2)
    
      p_s1_m , p_s1_s = multiply_gauss(f3_s1_m, f3_s1_s, f1_s1_m, f1_s1_s)
      p_s2_m , p_s2_s = multiply_gauss(f3_s2_m, f3_s2_s, f2_s2_m, f2_s2_s)
    
      return p_s1_m, p_s1_s, p_s2_m, p_s2_s
    
    ### Gibbs Sampler function (taken from another file)
    
    def gibbs_sampler(L):
      s1 = np.zeros(L)
      s2 = np.zeros(L)
      t = truncnorm.rvs(a=0, b=np.inf, size=L)
    
      #parameters
      mu_s1, mu_s2 = 1,1
      sig_s1, sig_s2 = 1,1
      sig_t = np.sqrt(5)
    
      #initialize
      s1[0] = 1
      s2[0] = 1
    
      #covariance matrix of p(s1,s2 | t)
      sigma_s_t = np.linalg.inv(np.array([[1/sig_t**2+1/sig_s1**2,-1/sig_t**2],[-1/sig_t**2,1/sig_s2**2+1/sig_t**2]]))
      sig_s1_t = np.sqrt(sigma_s_t[0][0])
      sig_s2_t = np.sqrt(sigma_s_t[1][1])
    
      chain_mu_s1 = np.zeros(L)
      chain_sig_s1 = np.zeros(L)
      chain_mu_s2 = np.zeros(L)
      chain_sig_s2 = np.zeros(L)
      chain_mu_s1[0] = mu_s1
      chain_mu_s2[0] = mu_s2
      chain_sig_s1[0] = sig_s1
      chain_sig_s2[0] = sig_s2
    
      start = time.time()
      #Gibbs sampler
      for k in range(L-1):
        #sampling t
        t[k+1] = truncnorm.rvs(a=(s2[k]-s1[k])/sig_t,b=np.inf,loc=(s1[k]-s2[k]),scale=sig_t) 
    
        #updating the mean of p(s1,s2 | t)
        mu_s_t = np.matmul(sigma_s_t,np.array([mu_s1/sig_s1**2+t[k+1]/sig_t**2,mu_s2/sig_s2**2-t[k+1]/sig_t**2]))
        
        #sampling s1  
        s1[k+1] = np.random.normal()*sig_s1_t + mu_s_t[0]
      
        #sampling s2
        s2[k+1] = np.random.normal()*sig_s2_t + mu_s_t[1]
    
        #save means and variances to assess stationnarity
        chain_mu_s1[k+1] = np.mean(s1[:k+1])
        chain_mu_s2[k+1] = np.mean(s2[:k+1])
        chain_sig_s1[k+1] = np.std(s1[:k+1])
        chain_sig_s2[k+1] = np.std(s2[:k+1])
        #print(k,s1)
        
      end = time.time()
      elapsed_t = end-start
    
      return s1,s2,t,elapsed_t,chain_mu_s1,chain_mu_s2,chain_sig_s1,chain_sig_s2
    
    # Main code for running file
    
    np.random.seed(123) # fix seed for same outcome
    
    # Parameters
    
    mu_1 = mu_2 = 1
    s_1 = s_2 = 1
    s_t = 5
    L = 1000  # samples
    burn_in = 500 # ?
    
    # Message-Passing
    p_s1_m, p_s1_s, p_s2_m, p_s2_s = posterior_s1_s2(mu_1, s_1, mu_2, s_2, s_t, y0=1)
    
    # Gibbs Sampler
    
    s1,s2,t,elapsed_t,chain_mu_s1,chain_mu_s2,chain_sig_s1,chain_sig_s2 = gibbs_sampler(1000)
    s1_stationary = s1[burn_in+1:]
    
    
    # Plots
    
    # Histogram and message-passing curve in same plot
    plt.hist(s1_stationary, density=True, bins=30, label='Gibbs Sampling', alpha=0.4)
    x = np.linspace(min(s1_stationary),max(s1_stationary), 100)
    plt.plot(x, norm(p_s1_m, np.sqrt(p_s1_s)).pdf(x), label='Message Passing')
    plt.legend()
    plt.xlabel('True skill level of Player 1')
    plt.ylabel('Probability')
    plt.show()
    plt.savefig('Q8_posterior_s1')
    
    """# Q9"""
    
    # Q9
    import pandas as pd
    import numpy as np
    from scipy.stats import truncnorm
    np.random.seed(469)
    
    print('Entered Q9')
    
    data = pd.read_csv("tennis.xlsx.csv")
    df = data[['winner_name','loser_name']]
    winners = df['winner_name'].unique()
    losers = df['loser_name'].unique()
    df_scores = pd.DataFrame(data=np.concatenate([winners,losers]),columns={"t1"})
    df_scores = df_scores.drop_duplicates()
    df_scores.reset_index(drop=True,inplace=True)
    mu = np.ones(len(df_scores))
    sd = np.ones(len(df_scores))
    df_scores['mu'] = mu
    df_scores['sd'] = sd
    df = df.rename(columns={'winner_name':'t1','loser_name':'t2'})
    
    df
    
    df_scores
    
    #Gibbs sampler function
    def  Gibbs(L, burn_in, team1, team2):
    
      #save means and variances to assess stationnarity
      chain_mu_s1 = np.ones(L-burn_in)
      chain_sig_s1 = np.ones(L-burn_in)
      chain_mu_s2 = np.ones(L-burn_in)
      chain_sig_s2 = np.ones(L-burn_in)
      #parameters
      mu_s1, mu_s2 = df_scores[df_scores['t1']==team1].iloc[0]['mu'],df_scores[df_scores['t1']==team2].iloc[0]['mu']
      sig_s1, sig_s2 = df_scores[df_scores['t1']==team1].iloc[0]['sd'],df_scores[df_scores['t1']==team2].iloc[0]['sd']
      sig_t = np.sqrt(5)
      #initialize
      s1 = np.zeros(L)
      s2 = np.zeros(L)
      t = np.zeros(L)
      t[0] = 1
      s1[0] = mu_s1
      s2[0] = mu_s2
    
      sigma_s = np.linalg.inv(np.array([[1/sig_t**2+1/sig_s1**2,-1/sig_t**2],[-1/sig_t**2,1/sig_s2**2+1/sig_t**2]]))
      sig_s1 = np.sqrt(sigma_s[0][0])
      sig_s2 = np.sqrt(sigma_s[1][1])
    
      pred = np.sign(s1[0]-s2[0])
      if pred==1:
        pred=1
      elif pred==-1:
        pred=0
      else:
        pred=np.random.randint(0, 1)
    
      # gibbs sampler
      for k in range(L-1):
    
        t[k+1] = truncnorm.rvs(a=0,b=np.inf,loc=(s1[k]-s2[k]),scale=sig_t) 
    
        mu_s = np.matmul(sigma_s,np.array([mu_s1/sig_s1**2+t[k+1]/sig_t**2,mu_s2/sig_s2**2-t[k+1]/sig_t**2]))
    
        s1[k+1] = np.random.normal()*sig_s1 + mu_s[0]
    
        s2[k+1] = np.random.normal()*sig_s2 + mu_s[1]
    
        if k>burn_in:
          chain_mu_s1[k-burn_in] = np.mean(s1[burn_in:k+1])
          chain_mu_s2[k-burn_in] = np.mean(s2[burn_in:k+1])
          chain_sig_s1[k-burn_in] = np.std(s1[burn_in:k+1])
          chain_sig_s2[k-burn_in] = np.std(s2[burn_in:k+1])
    
      return np.mean(chain_mu_s1),np.mean(chain_sig_s1), np.mean(chain_mu_s2), np.mean(chain_sig_s2), pred
    
    
    pred_rate = np.zeros(len(df))
    
    for i in range(len(df)):
      result  = Gibbs(5000, 2000, df.iloc[i]['t1'], df.iloc[i]['t2'])
      df_scores.loc[df_scores['t1']==df.iloc[i]['t1'],['mu']]=result[0]
      df_scores.loc[df_scores['t1']==df.iloc[i]['t1'],['sd']]=result[1]
      df_scores.loc[df_scores['t1']==df.iloc[i]['t2'],['mu']]=result[2]
      df_scores.loc[df_scores['t1']==df.iloc[i]['t2'],['sd']]=result[3]
      pred_rate[i] = result[4]
    ranking = df_scores.sort_values('mu', ascending=False).reset_index().drop(columns=['index'])
    ranking
    
    np.mean(pred_rate)
    
    from scipy.stats import binom_test
    test_pred = binom_test(sum(pred_rate), n=len(df), p=0.5)
    print(test_pred)
    print('is this smaller than our critical value?')
    print(test_pred<0.001)
    
    """# Q10"""
    
    # Q10
    
    import numpy as np
    import matplotlib.pyplot as plt
    from scipy.stats import truncnorm
    from scipy.stats import norm
    import pandas as pd
    
    print('Entered Q10')
    
    np.random.seed(469)
    SerieA = pd.read_csv('SerieA.csv')
    df = SerieA
    df = df.drop(columns=['yyyy-mm-dd', 'HH:MM'])
    df = df.assign(s1_win = np.sign(df['score1']-df['score2']))
    df = df.drop(columns=['score1', 'score2'])
    df1 = df.loc[df['s1_win']>0, ['team1', 'team2', 's1_win']].drop(columns = ['s1_win'])
    df2 = df.loc[df['s1_win']<0, ['team1', 'team2', 's1_win']].drop(columns = ['s1_win'])
    df3 = df.loc[df['s1_win']==0, ['team1', 'team2', 's1_win']]
    df2 = df2.rename(columns = {'team1':'t2','team2':'t1'})
    df1 = df1.rename(columns = {'team1':'t1','team2':'t2'})
    df3 = df3.rename(columns = {'team1':'t1', 'team2':'t2'})
    df = pd.concat([df1,df2, df3]).sort_index().fillna(1)
    
    mu = pd.DataFrame([1]*20, columns=['mu'])
    sd = pd.DataFrame([1]*20, columns=['sd'])
    df_scores = df.drop(columns=['t2', 's1_win']).drop_duplicates()
    df_scores = df_scores.reset_index().drop(columns=['index'])
    df_scores = pd.concat([df_scores, mu, sd], axis = 1)
    
    
    #Gibbs sampler function
    def  Gibbs(L, burn_in, team1, team2, winner_exist):
    
      #save means and variances to assess stationnarity
      chain_mu_s1 = np.ones(L-burn_in)
      chain_sig_s1 = np.ones(L-burn_in)
      chain_mu_s2 = np.ones(L-burn_in)
      chain_sig_s2 = np.ones(L-burn_in)
      #parameters
      mu_s1, mu_s2 = df_scores[df_scores['t1']==team1].iloc[0]['mu'],df_scores[df_scores['t1']==team2].iloc[0]['mu']
      sig_s1, sig_s2 = df_scores[df_scores['t1']==team1].iloc[0]['sd'],df_scores[df_scores['t1']==team2].iloc[0]['sd']
      sig_t = np.sqrt(5)
      #initialize
      s1 = np.zeros(L)
      s2 = np.zeros(L)
      t = np.zeros(L)
      t[0] = 1
      s1[0] = mu_s1
      s2[0] = mu_s2
    
      sigma_s = np.linalg.inv(np.array([[1/sig_t**2+1/sig_s1**2,-1/sig_t**2],[-1/sig_t**2,1/sig_s2**2+1/sig_t**2]]))
      sig_s1 = np.sqrt(sigma_s[0][0])
      sig_s2 = np.sqrt(sigma_s[1][1])
    
      delta = 1
      deltaminus = -1
      pred = 0
      if s1[0]-s2[0] > delta:
        pred=1
      elif s1[0]-s2[0] < deltaminus:
        pred=-1
      else:
        pred=0
    
      if winner_exist == 0 and pred == 0:
        pred = 1
      elif winner_exist == 1 and pred == 1:
        pred = 1
      else:
        pred = 0
    
    
      # gibbs sampler
      for k in range(L-1):
    
        if winner_exist==0:
          t[k+1] = truncnorm.rvs(a=-np.inf,b=np.inf,loc=(s1[k]-s2[k]),scale=sig_t)
        else:
           t[k+1] = truncnorm.rvs(a=0,b=np.inf,loc=(s1[k]-s2[k]),scale=sig_t) 
    
        mu_s = np.matmul(sigma_s,np.array([mu_s1/sig_s1**2+t[k+1]/sig_t**2,mu_s2/sig_s2**2-t[k+1]/sig_t**2]))
    
        s1[k+1] = np.random.normal()*sig_s1 + mu_s[0]
    
        s2[k+1] = np.random.normal()*sig_s2 + mu_s[1]
    
        if k>burn_in:
          chain_mu_s1[k-burn_in] = np.mean(s1[burn_in:k+1])
          chain_mu_s2[k-burn_in] = np.mean(s2[burn_in:k+1])
          chain_sig_s1[k-burn_in] = np.std(s1[burn_in:k+1])
          chain_sig_s2[k-burn_in] = np.std(s2[burn_in:k+1])
    
      return np.mean(chain_mu_s1),np.mean(chain_sig_s1), np.mean(chain_mu_s2), np.mean(chain_sig_s2), pred
    
    pred_rate = np.zeros(len(df))
    q=1
    for i in range(len(df)):
      if df.iloc[i]['s1_win']==0:
        q=q+1
        if q==20:
          plt.figure(1)
          x = np.linspace(-10, 50, 1000)
          plt.plot(x,norm.pdf(x, np.array(df_scores.loc[df_scores['t1']==df.iloc[i]['t1'],['mu']])[0][0], np.array(df_scores.loc[df_scores['t1']==df.iloc[i]['t1'],['sd']])[0][0]), color = 'red')
          plt.xlim(0,10)
          plt.figure(2)
          x = np.linspace(-10, 50, 1000)
          plt.plot(x,norm.pdf(x, np.array(df_scores.loc[df_scores['t1']==df.iloc[i]['t2'],['mu']])[0][0], np.array(df_scores.loc[df_scores['t1']==df.iloc[i]['t2'],['sd']])[0][0]), color = 'red')
          plt.xlim(0,10)
          
      result  = Gibbs(5000, 2000, df.iloc[i]['t1'], df.iloc[i]['t2'], df.iloc[i]['s1_win'])
      df_scores.loc[df_scores['t1']==df.iloc[i]['t1'],['mu']]=result[0]
      df_scores.loc[df_scores['t1']==df.iloc[i]['t1'],['sd']]=result[1]
      df_scores.loc[df_scores['t1']==df.iloc[i]['t2'],['mu']]=result[2]
      df_scores.loc[df_scores['t1']==df.iloc[i]['t2'],['sd']]=result[3]
      pred_rate[i] = result[4]
      if df.iloc[i]['s1_win']==0:
        if q==20:
          plt.figure(1)
          x = np.linspace(-10, 50, 1000)
          plt.plot(x,norm.pdf(x, np.array(df_scores.loc[df_scores['t1']==df.iloc[i]['t1'],['mu']])[0][0], np.array(df_scores.loc[df_scores['t1']==df.iloc[i]['t1'],['sd']])[0][0]), color = 'blue')
          plt.xlim(0,10)
          plt.figure(2)
          x = np.linspace(-10, 50, 1000)
          plt.plot(x,norm.pdf(x, np.array(df_scores.loc[df_scores['t1']==df.iloc[i]['t2'],['mu']])[0][0], np.array(df_scores.loc[df_scores['t1']==df.iloc[i]['t2'],['sd']])[0][0]), color = 'blue')
          plt.xlim(0,10)
    
    print(np.mean(pred_rate))
    ranking = df_scores.sort_values('mu', ascending=False).reset_index().drop(columns=['index'])
    ranking






### Main ###

# Make runnable

if __name__ == "__main__":
    main()
